{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f552017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd35db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f2ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Introduction to the data ingestion module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573272df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188fe042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion module loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter)\n",
    "print(\"Data ingestion module loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163c76d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81d51b05",
   "metadata": {},
   "source": [
    "## understand the document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b50aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure:\n",
      "This is a sample document for data ingestion.\n",
      "{\"source\": \"sample.txt\", \"page\": 1, \"title\": \"Sample Document\", \"author\": \"John Doe\"}\n",
      "\n",
      " Metadata is crucial for filtering and retrieval in RAG systems.\n",
      "Tracking document source\n",
      "providing context in responses\n",
      "debuging and auditing\n"
     ]
    }
   ],
   "source": [
    "##create a simple document\n",
    "doc = Document(page_content=\"This is a sample document for data ingestion.\", \n",
    "               metadata={\"source\": \"sample.txt\",\n",
    "                         \"page\": 1,\n",
    "                         \"title\": \"Sample Document\",\n",
    "                         \"author\": \"John Doe\" })\n",
    "print(f\"Document Structure:\")\n",
    "print(doc.page_content)\n",
    "print(json.dumps(doc.metadata))\n",
    "print(\"\\n Metadata is crucial for filtering and retrieval in RAG systems.\")\n",
    "print(\"Tracking document source\")\n",
    "print(\"providing context in responses\")\n",
    "print(\"debuging and auditing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1083aa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe89d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "712f6461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing\n",
      "Text files directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files\n",
      "\n",
      "Sample text dictionary created:\n",
      "Output directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files\n",
      "\n",
      "Writing: python.intro.txt\n",
      "  Preview: Python is a high-level, interpreted programming language kno...\n",
      "  ✓ Successfully written\n",
      "\n",
      "Writing: machine_intro.txt\n",
      "  Preview: Machine Learning is a subset of artificial intelligence that...\n",
      "  ✓ Successfully written\n",
      "\n",
      "Sample text files written to 'data/txt_files/' directory (under Data_Ingestion_Parsing).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create data/txt_files folder in the current Data_Ingestion_Parsing directory\n",
    "txt_files_dir = os.path.join(os.getcwd(), 'data', 'txt_files')\n",
    "os.makedirs(txt_files_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Text files directory: {txt_files_dir}\\n\")\n",
    "\n",
    "sample_text = {\n",
    "    os.path.join(txt_files_dir, \"python.intro.txt\"): \"\"\"Python is a high-level, interpreted programming language known for its simple and readable syntax. It supports multiple programming paradigms and is widely used in web development, data science, machine learning, and automation.\"\"\",\n",
    "    os.path.join(txt_files_dir, \"machine_intro.txt\"): \"\"\"Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.\"\"\"    \n",
    "}\n",
    "\n",
    "print(\"Sample text dictionary created:\")\n",
    "print(f\"Output directory: {txt_files_dir}\\n\")\n",
    "\n",
    "for key, value in sample_text.items():\n",
    "    print(f\"Writing: {os.path.basename(key)}\")\n",
    "    print(f\"  Preview: {value[:60]}...\")\n",
    "    try:\n",
    "        with open(key, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(value)\n",
    "        print(f\"  ✓ Successfully written\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\\n\")\n",
    "\n",
    "print(\"Sample text files written to 'data/txt_files/' directory (under Data_Ingestion_Parsing).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21791435",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "### read the single file and create document object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7854aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Python intro document:\n",
      "Type: <class 'list'>\n",
      "Number of documents: 1\n",
      "Content preview: Python is a high-level, interpreted programming language known for its simple and readable syntax. I...\n",
      "\n",
      "metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt'}\n",
      "\n",
      "Loaded Machine Learning intro document:\n",
      "Type: <class 'list'>\n",
      "Number of documents: 1\n",
      "Content preview: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and i...\n",
      "\n",
      "metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load the first text file (python.intro.txt)\n",
    "python_file_path = os.path.join(txt_files_dir, \"python.intro.txt\")\n",
    "loader = TextLoader(python_file_path, encoding=\"utf-8\")\n",
    "python_docs = loader.load()\n",
    "\n",
    "print(\"Loaded Python intro document:\")\n",
    "print(f\"Type: {type(python_docs)}\")\n",
    "print(f\"Number of documents: {len(python_docs)}\")\n",
    "print(f\"Content preview: {python_docs[0].page_content[:100]}...\\n\")\n",
    "print(f\"metadata: {python_docs[0].metadata}\\n\")\n",
    "\n",
    "# Load the second text file (machine_intro.txt)\n",
    "ml_file_path = os.path.join(txt_files_dir, \"machine_intro.txt\")\n",
    "loader = TextLoader(ml_file_path, encoding=\"utf-8\")\n",
    "ml_docs = loader.load()\n",
    "\n",
    "print(\"Loaded Machine Learning intro document:\")\n",
    "print(f\"Type: {type(ml_docs)}\")\n",
    "print(f\"Number of documents: {len(ml_docs)}\")\n",
    "print(f\"Content preview: {ml_docs[0].page_content[:100]}...\\n\")\n",
    "print(f\"metadata: {ml_docs[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75762c4f",
   "metadata": {},
   "source": [
    "### DirectoryLoader - multiple files ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43078453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1359.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents from DirectoryLoader:\n",
      "Type: <class 'list'>\n",
      "\n",
      "Document 1:\n",
      "  Content preview: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and i...\n",
      "  Metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt\n",
      "\n",
      "Document 2:\n",
      "  Content preview: Python is a high-level, interpreted programming language known for its simple and readable syntax. I...\n",
      "  Metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt'}\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt\n",
      "\n",
      "Advantages of DirectoryLoader:\n",
      "1. Efficiently loads multiple files from a directory structure.\n",
      "2. Supports various file types through different loader classes.\n",
      "3. Simplifies batch processing of documents for ingestion.\n",
      "\n",
      "Disadvantages of DirectoryLoader:\n",
      "1. Limited to files within a specified directory; may miss external sources.\n",
      "2. Requires appropriate loader classes for different file formats.\n",
      "3. can be memory intensive for larger directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# Load all text files from the txt_files directory\n",
    "loader = DirectoryLoader(\n",
    "    path=txt_files_dir, glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader, show_progress=True,\n",
    "    loader_kwargs={'encoding': 'utf-8'})\n",
    "docs = loader.load()\n",
    "print(f\"Loaded documents from DirectoryLoader:\")\n",
    "print(f\"Type: {type(docs)}\")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Content preview: {doc.page_content[:100]}...\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n",
    "    print(f\"  source: {doc.metadata['source']}\")\n",
    "    print(f\"  source: {doc.metadata.get('source')}\")\n",
    "\n",
    "# advantages and disadvantages of DirectoryLoader\n",
    "print(\"\\nAdvantages of DirectoryLoader:\")\n",
    "print(\"1. Efficiently loads multiple files from a directory structure.\")\n",
    "print(\"2. Supports various file types through different loader classes.\")\n",
    "print(\"3. Simplifies batch processing of documents for ingestion.\")\n",
    "\n",
    "print(\"\\nDisadvantages of DirectoryLoader:\")\n",
    "print(\"1. Limited to files within a specified directory; may miss external sources.\")\n",
    "print(\"2. Requires appropriate loader classes for different file formats.\")\n",
    "print(\"3. can be memory intensive for larger directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77e3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
