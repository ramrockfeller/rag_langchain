{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f552017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd35db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f2ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Introduction to the data ingestion module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573272df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188fe042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion module loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter)\n",
    "print(\"Data ingestion module loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163c76d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81d51b05",
   "metadata": {},
   "source": [
    "## understand the document structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b50aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure:\n",
      "This is a sample document for data ingestion.\n",
      "{\"source\": \"sample.txt\", \"page\": 1, \"title\": \"Sample Document\", \"author\": \"John Doe\"}\n",
      "\n",
      " Metadata is crucial for filtering and retrieval in RAG systems.\n",
      "Tracking document source\n",
      "providing context in responses\n",
      "debuging and auditing\n"
     ]
    }
   ],
   "source": [
    "##create a simple document\n",
    "doc = Document(page_content=\"This is a sample document for data ingestion.\", \n",
    "               metadata={\"source\": \"sample.txt\",\n",
    "                         \"page\": 1,\n",
    "                         \"title\": \"Sample Document\",\n",
    "                         \"author\": \"John Doe\" })\n",
    "print(f\"Document Structure:\")\n",
    "print(doc.page_content)\n",
    "print(json.dumps(doc.metadata))\n",
    "print(\"\\n Metadata is crucial for filtering and retrieval in RAG systems.\")\n",
    "print(\"Tracking document source\")\n",
    "print(\"providing context in responses\")\n",
    "print(\"debuging and auditing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1083aa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe89d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "712f6461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing\n",
      "Text files directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files\n",
      "\n",
      "Sample text dictionary created:\n",
      "Output directory: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files\n",
      "\n",
      "Writing: python.intro.txt\n",
      "  Preview: Python is a high-level, interpreted programming language kno...\n",
      "  ✓ Successfully written\n",
      "\n",
      "Writing: machine_intro.txt\n",
      "  Preview: Machine Learning is a subset of artificial intelligence that...\n",
      "  ✓ Successfully written\n",
      "\n",
      "Sample text files written to 'data/txt_files/' directory (under Data_Ingestion_Parsing).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create data/txt_files folder in the current Data_Ingestion_Parsing directory\n",
    "txt_files_dir = os.path.join(os.getcwd(), 'data', 'txt_files')\n",
    "os.makedirs(txt_files_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Text files directory: {txt_files_dir}\\n\")\n",
    "\n",
    "sample_text = {\n",
    "    os.path.join(txt_files_dir, \"python.intro.txt\"): \"\"\"Python is a high-level, interpreted programming language known for its simple and readable syntax. It supports multiple programming paradigms and is widely used in web development, data science, machine learning, and automation.\"\"\",\n",
    "    os.path.join(txt_files_dir, \"machine_intro.txt\"): \"\"\"Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.\"\"\"    \n",
    "}\n",
    "\n",
    "print(\"Sample text dictionary created:\")\n",
    "print(f\"Output directory: {txt_files_dir}\\n\")\n",
    "\n",
    "for key, value in sample_text.items():\n",
    "    print(f\"Writing: {os.path.basename(key)}\")\n",
    "    print(f\"  Preview: {value[:60]}...\")\n",
    "    try:\n",
    "        with open(key, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(value)\n",
    "        print(f\"  ✓ Successfully written\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\\n\")\n",
    "\n",
    "print(\"Sample text files written to 'data/txt_files/' directory (under Data_Ingestion_Parsing).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21791435",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "### read the single file and create document object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7854aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Python intro document:\n",
      "Type: <class 'list'>\n",
      "Number of documents: 1\n",
      "Content preview: Python is a high-level, interpreted programming language known for its simple and readable syntax. I...\n",
      "\n",
      "metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt'}\n",
      "\n",
      "Loaded Machine Learning intro document:\n",
      "Type: <class 'list'>\n",
      "Number of documents: 1\n",
      "Content preview: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and i...\n",
      "\n",
      "metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Load the first text file (python.intro.txt)\n",
    "python_file_path = os.path.join(txt_files_dir, \"python.intro.txt\")\n",
    "loader = TextLoader(python_file_path, encoding=\"utf-8\")\n",
    "python_docs = loader.load()\n",
    "\n",
    "print(\"Loaded Python intro document:\")\n",
    "print(f\"Type: {type(python_docs)}\")\n",
    "print(f\"Number of documents: {len(python_docs)}\")\n",
    "print(f\"Content preview: {python_docs[0].page_content[:100]}...\\n\")\n",
    "print(f\"metadata: {python_docs[0].metadata}\\n\")\n",
    "\n",
    "# Load the second text file (machine_intro.txt)\n",
    "ml_file_path = os.path.join(txt_files_dir, \"machine_intro.txt\")\n",
    "loader = TextLoader(ml_file_path, encoding=\"utf-8\")\n",
    "ml_docs = loader.load()\n",
    "\n",
    "print(\"Loaded Machine Learning intro document:\")\n",
    "print(f\"Type: {type(ml_docs)}\")\n",
    "print(f\"Number of documents: {len(ml_docs)}\")\n",
    "print(f\"Content preview: {ml_docs[0].page_content[:100]}...\\n\")\n",
    "print(f\"metadata: {ml_docs[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75762c4f",
   "metadata": {},
   "source": [
    "### DirectoryLoader - multiple files ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43078453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 810.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents from DirectoryLoader:\n",
      "Type: <class 'list'>\n",
      "\n",
      "Document 1:\n",
      "  Content preview: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and i...\n",
      "  Metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt\n",
      "\n",
      "Document 2:\n",
      "  Content preview: Python is a high-level, interpreted programming language known for its simple and readable syntax. I...\n",
      "  Metadata: {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt'}\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt\n",
      "  source: /home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt\n",
      "\n",
      "Advantages of DirectoryLoader:\n",
      "1. Efficiently loads multiple files from a directory structure.\n",
      "2. Supports various file types through different loader classes.\n",
      "3. Simplifies batch processing of documents for ingestion.\n",
      "\n",
      "Disadvantages of DirectoryLoader:\n",
      "1. Limited to files within a specified directory; may miss external sources.\n",
      "2. Requires appropriate loader classes for different file formats.\n",
      "3. can be memory intensive for larger directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# Load all text files from the txt_files directory\n",
    "loader = DirectoryLoader(\n",
    "    path=txt_files_dir, glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader, show_progress=True,\n",
    "    loader_kwargs={'encoding': 'utf-8'})\n",
    "docs = loader.load()\n",
    "print(f\"Loaded documents from DirectoryLoader:\")\n",
    "print(f\"Type: {type(docs)}\")\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"  Content preview: {doc.page_content[:100]}...\")\n",
    "    print(f\"  Metadata: {doc.metadata}\")\n",
    "    print(f\"  source: {doc.metadata['source']}\")\n",
    "    print(f\"  source: {doc.metadata.get('source')}\")\n",
    "\n",
    "# advantages and disadvantages of DirectoryLoader\n",
    "print(\"\\nAdvantages of DirectoryLoader:\")\n",
    "print(\"1. Efficiently loads multiple files from a directory structure.\")\n",
    "print(\"2. Supports various file types through different loader classes.\")\n",
    "print(\"3. Simplifies batch processing of documents for ingestion.\")\n",
    "\n",
    "print(\"\\nDisadvantages of DirectoryLoader:\")\n",
    "print(\"1. Limited to files within a specified directory; may miss external sources.\")\n",
    "print(\"2. Requires appropriate loader classes for different file formats.\")\n",
    "print(\"3. can be memory intensive for larger directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f008fd0",
   "metadata": {},
   "source": [
    "### Text splitter Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b76aa5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}, page_content='Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.\\nKey features of Machine Learning include:\\n1. Data-driven learning\\n2. Pattern recognition\\n3. Predictive analytics\\n4. Adaptability to new data\\n5. Automation of decision-making processes\\n6. Support for various data types (structured, unstructured)\\n7. Integration with big data technologies\\n8. Continuous improvement through feedback loops\\n9. Wide range of algorithms (supervised, unsupervised, reinforcement learning)\\n10. Applications across diverse industries such as healthcare, finance, and marketing.\\nSome popular Machine Learning frameworks and libraries are TensorFlow, PyTorch, Scikit-learn, and Keras, which facilitate the development and deployment of ML models.'), Document(metadata={'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/python.intro.txt'}, page_content=\"Python is a high-level, interpreted programming language known for its simple and readable syntax. It supports multiple programming paradigms and is widely used in web development, data science, machine learning, and automation.\\nPython's extensive standard library and vibrant community contribute to its versatility and ease of use, making it a popular choice for both beginners and experienced developers.\\nSome key features of Python include:\\n1. Easy-to-read syntax\\n2. Dynamic typing\\n3. Extensive libraries and frameworks\\n4. Cross-platform compatibility\\n5. Strong community support\\n6. Integration capabilities with other languages and tools\\n7. Support for multiple programming paradigms (procedural, object-oriented, functional)\\n8. Robust support for data science and machine learning through libraries like NumPy, pandas, and TensorFlow.\\n\")]\n"
     ]
    }
   ],
   "source": [
    "### Different Text Splitting Strategies\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53942aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2d31def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 310, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning is a subset of artificial intelligence that enables computer systems to learn and i {'source': '/home/ram/apps/langchain/project1/rag_langchain/Data_Ingestion_Parsing/data/txt_files/machine_intro.txt'}\n",
      "\n",
      "Character Text Splitter produced 6 chunks:\n",
      "Chunk 1: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.\n",
      "Chunk 2: Key features of Machine Learning include:\n",
      "1. Data-driven learning\n",
      "2. Pattern recognition\n",
      "3. Predictive analytics\n",
      "4. Adaptability to new data\n",
      "5. Automation of decision-making processes\n"
     ]
    }
   ],
   "source": [
    "### Method -1 - Character Text Splitter\n",
    "print(docs[0].page_content[:100] , docs[0].metadata)\n",
    "text = docs[0].page_content;\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # split by new line\n",
    "    chunk_size=200, # number of characters in each chunk\n",
    "    chunk_overlap=50, # number of characters to overlap between chunks\n",
    "    length_function=len, # function to calculate length\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"\\nCharacter Text Splitter produced {len(char_chunks)} chunks:\")\n",
    "print(f\"Chunk 1: {char_chunks[0]}\")\n",
    "print(f\"Chunk 2: {char_chunks[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ee28520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.', 'Key features of Machine Learning include:\\n1. Data-driven learning\\n2. Pattern recognition\\n3. Predictive analytics\\n4. Adaptability to new data\\n5. Automation of decision-making processes', '5. Automation of decision-making processes\\n6. Support for various data types (structured, unstructured)\\n7. Integration with big data technologies\\n8. Continuous improvement through feedback loops', '8. Continuous improvement through feedback loops\\n9. Wide range of algorithms (supervised, unsupervised, reinforcement learning)', '10. Applications across diverse industries such as healthcare, finance, and marketing.', 'Some popular Machine Learning frameworks and libraries are TensorFlow, PyTorch, Scikit-learn, and Keras, which facilitate the development and deployment of ML models.']\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc9293d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "RECURSIVE CHARACTER TEXT SPLITTER\n",
      "\n",
      "Recursive Character Text Splitter produced 6 chunks:\n",
      "Chunk 1: Machine Learning is a subset of artificial intelligence that enables computer systems to learn and improve from data without being explicitly programmed. ML algorithms identify patterns and make\n",
      "Chunk 1: patterns and make predictions, powering applications like recommendation systems, image recognition, and natural language processing.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---\\n\")\n",
    "print(\"RECURSIVE CHARACTER TEXT SPLITTER\")\n",
    "### Method -2 - Recursive Character Text Splitter\n",
    "recursive_char_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # hierarchy of separators\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "recursive_char_chunks = recursive_char_splitter.split_text(text)\n",
    "print(f\"\\nRecursive Character Text Splitter produced {len(recursive_char_chunks)} chunks:\")\n",
    "print(f\"Chunk 1: {recursive_char_chunks[0]}\")\n",
    "print(f\"Chunk 1: {recursive_char_chunks[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8cb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
